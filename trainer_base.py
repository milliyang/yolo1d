#!/usr/bin/env python3
"""
YOLO1D è®­ç»ƒå™¨åŸºç±»
ç»Ÿä¸€è®­ç»ƒé€»è¾‘ï¼Œå‡å°‘é‡å¤ä»£ç 
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torchmetrics.detection import MeanAveragePrecision
from tqdm import tqdm
import yaml
import os
from typing import Dict, List, Optional, Tuple, Any
import logging
from pathlib import Path

from yolo1d_model import create_yolo1d_model
from yolo1d_loss import YOLO1DLoss, compute_loss
from utils import plot_validation_predictions, postprocess_for_metrics


class YOLO1DError(Exception):
    """YOLO1Dä¸“ç”¨å¼‚å¸¸ç±»"""
    pass


class ModelInitializationError(YOLO1DError):
    """æ¨¡å‹åˆå§‹åŒ–é”™è¯¯"""
    pass


class TrainingError(YOLO1DError):
    """è®­ç»ƒé”™è¯¯"""
    pass


class ConfigError(YOLO1DError):
    """é…ç½®é”™è¯¯"""
    pass


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = self.load_config(config_path)
        self.validate_config()
    
    def load_config(self, path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            return config
        except Exception as e:
            raise ConfigError(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ {path}: {e}")
    
    def validate_config(self):
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        required_keys = [
            'model_size', 'num_classes', 'input_channels', 
            'input_length', 'epochs', 'batch_size', 'learning_rate'
        ]
        
        missing_keys = [key for key in required_keys if key not in self.config]
        if missing_keys:
            raise ConfigError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_keys}")
        
        # éªŒè¯æ•°å€¼èŒƒå›´
        if self.config['learning_rate'] <= 0:
            raise ConfigError("å­¦ä¹ ç‡å¿…é¡»å¤§äº0")
        
        if self.config['batch_size'] <= 0:
            raise ConfigError("æ‰¹å¤§å°å¿…é¡»å¤§äº0")
        
        if self.config['epochs'] <= 0:
            raise ConfigError("è®­ç»ƒè½®æ•°å¿…é¡»å¤§äº0")
    
    def get_training_config(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒé…ç½®"""
        return self.config
    
    def update_config(self, updates: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        self.config.update(updates)
        self.validate_config()


class BaseTrainer:
    """è®­ç»ƒå™¨åŸºç±»ï¼ŒåŒ…å«é€šç”¨åŠŸèƒ½"""
    
    def __init__(self, 
                 model: nn.Module,
                 train_loader: torch.utils.data.DataLoader,
                 val_loader: torch.utils.data.DataLoader,
                 config: Dict[str, Any],
                 device: torch.device,
                 resume_from: Optional[str] = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: YOLO1Dæ¨¡å‹
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            config: è®­ç»ƒé…ç½®
            device: è®¡ç®—è®¾å¤‡
            resume_from: æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = device
        self.start_epoch = 0
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # ä¿®å¤æ­¥é•¿é—®é¢˜
        self.fix_stride_issue()
        
        # è®¾ç½®è®­ç»ƒç»„ä»¶
        self.setup_training_components()
        
        # è®¾ç½®ç›‘æ§
        self.setup_monitoring()
        
        # å¦‚æœæŒ‡å®šäº†æ¢å¤æ£€æŸ¥ç‚¹ï¼Œåˆ™åŠ è½½
        if resume_from:
            self.load_checkpoint(resume_from)
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        if not self.logger.handlers:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
    
    def fix_stride_issue(self):
        """ä¿®å¤æ­¥é•¿é—®é¢˜"""
        self.logger.info("ğŸ”§ ä¿®å¤æ­¥é•¿é—®é¢˜")
        
        input_length = self.config['input_length']
        
        if input_length == 1024:
            correct_strides = [8, 16, 32]
        else:
            correct_strides = [input_length // 128, input_length // 64, input_length // 32]
        
        self.logger.info(f"  è¾“å…¥é•¿åº¦: {input_length}")
        self.logger.info(f"  è®¡ç®—å‡ºçš„æ­£ç¡®æ­¥é•¿: {correct_strides}")
        
        with torch.no_grad():
            for i, stride in enumerate(correct_strides):
                self.model.detect.stride[i] = float(stride)
        
        self.logger.info(f"  ä¿®å¤åçš„æ­¥é•¿: {self.model.detect.stride}")
    
    def setup_training_components(self):
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        # å®šä¹‰æŸå¤±è¶…å‚æ•°
        hyp = self.config.get('hyp', {})
        self.logger.info(f"ä½¿ç”¨æŸå¤±è¶…å‚æ•°: {hyp}")

        # æŸå¤±å‡½æ•°
        self.criterion = YOLO1DLoss(
            num_classes=self.config['num_classes'],
            reg_max=self.config.get('reg_max', 16),
            use_dfl=True,
            hyp=hyp
        )
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=self.config.get('weight_decay', 0.0005)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.setup_scheduler()
    
    def setup_scheduler(self):
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler_config = self.config.get('scheduler', {})
        scheduler_type = scheduler_config.get('type', 'cosine')
        
        if scheduler_type == 'onecycle':
            # ä½¿ç”¨OneCycleLR (train_simple.pyçš„æˆåŠŸç­–ç•¥)
            self.scheduler = optim.lr_scheduler.OneCycleLR(
                self.optimizer,
                max_lr=scheduler_config.get('max_lr', self.config['learning_rate']),
                epochs=self.config['epochs'],
                steps_per_epoch=len(self.train_loader)
            )
            self.logger.info("âœ… ä½¿ç”¨OneCycleLRè°ƒåº¦å™¨")
        elif scheduler_type == 'cosine':
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config['epochs'],
                eta_min=scheduler_config.get('eta_min', self.config['learning_rate'] * 0.01)
            )
            self.logger.info("âœ… ä½¿ç”¨CosineAnnealingLRè°ƒåº¦å™¨")
        else:
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.get('lr_step_size', 30),
                gamma=self.config.get('lr_gamma', 0.1)
            )
            self.logger.info("âœ… ä½¿ç”¨StepLRè°ƒåº¦å™¨")
    
    def setup_monitoring(self):
        """è®¾ç½®ç›‘æ§"""
        # TensorBoardæ—¥å¿—
        self.log_dir = Path(f"runs/{self.config.get('run_name', 'experiment')}")
        self.writer = SummaryWriter(str(self.log_dir))

        # æƒé‡ä¿å­˜ç›®å½•
        self.weights_dir = self.log_dir / 'weights'
        self.weights_dir.mkdir(parents=True, exist_ok=True)
        
        # mAPæŒ‡æ ‡
        self.map_metric = MeanAveragePrecision(
            box_format='xyxy',
            iou_type='bbox'
        )
        
        # è®­ç»ƒå†å²
        self.train_losses = []
        self.val_losses = []
        self.mAPs = []
        self.best_map = 0.0
        
        # æ—©åœ
        self.early_stopping = EarlyStopping(
            patience=self.config.get('patience', 10),
            min_delta=self.config.get('min_delta', 0.001)
        )
    
    def load_checkpoint(self, checkpoint_path: str) -> bool:
        """ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçŠ¶æ€ï¼Œæ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ã€‚"""
        try:
            resume_path = Path(checkpoint_path)
            if not resume_path.is_file():
                self.logger.error(f"âŒ æ¢å¤è®­ç»ƒå¤±è´¥ï¼šæ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶ -> {resume_path}")
                return False

            self.logger.info(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ£€æŸ¥ç‚¹: {resume_path.resolve()}")
            
            checkpoint = torch.load(resume_path, map_location=self.device)
            
            # åŠ è½½æ¨¡å‹æƒé‡
            if 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.logger.info("âœ“ æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
            
            # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
            if 'optimizer_state_dict' in checkpoint:
                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                self.logger.info("âœ“ ä¼˜åŒ–å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")
            
            # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€
            if 'scheduler_state_dict' in checkpoint:
                self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                self.logger.info("âœ“ è°ƒåº¦å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")
            
            # åŠ è½½è®­ç»ƒå†å²
            if 'train_losses' in checkpoint:
                self.train_losses = checkpoint['train_losses']
            if 'val_losses' in checkpoint:
                self.val_losses = checkpoint['val_losses']
            if 'mAPs' in checkpoint:
                self.mAPs = checkpoint['mAPs']
            if 'best_map' in checkpoint:
                self.best_map = checkpoint['best_map']
            
            # è®¾ç½®èµ·å§‹epoch
            if 'epoch' in checkpoint:
                self.start_epoch = checkpoint['epoch'] + 1
                self.logger.info(f"âœ“ å°†ä»ç¬¬ {self.start_epoch} ä¸ªepochå¼€å§‹è®­ç»ƒ")
            
            # éªŒè¯é…ç½®ä¸€è‡´æ€§
            if 'config' in checkpoint:
                self._validate_config_consistency(checkpoint['config'])
            
            self.logger.info(f"âœ“ æ£€æŸ¥ç‚¹æ¢å¤å®Œæˆï¼å°†ä»ç¬¬ {self.start_epoch} ä¸ªepochç»§ç»­è®­ç»ƒ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {str(e)}", exc_info=True)
            return False
    
    def _validate_config_consistency(self, saved_config: Dict[str, Any]):
        """éªŒè¯é…ç½®ä¸€è‡´æ€§"""
        key_configs = ['model_size', 'num_classes', 'input_channels', 'input_length']
        config_mismatch = []
        
        for key in key_configs:
            if key in saved_config and key in self.config:
                if saved_config[key] != self.config[key]:
                    config_mismatch.append(f"{key}: {saved_config[key]} -> {self.config[key]}")
        
        if config_mismatch:
            self.logger.warning("âš ï¸  é…ç½®ä¸åŒ¹é…:")
            for mismatch in config_mismatch:
                self.logger.warning(f"    {mismatch}")
            self.logger.warning("å»ºè®®ä½¿ç”¨ä¸æ£€æŸ¥ç‚¹ç›¸åŒçš„é…ç½®è¿›è¡Œæ¢å¤è®­ç»ƒ")
        else:
            self.logger.info("âœ“ é…ç½®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'config': self.config,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'mAPs': self.mAPs,
            'best_map': self.best_map
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_path = self.weights_dir / f"checkpoint_epoch_{epoch}.pth"
        torch.save(checkpoint, latest_path)
        self.logger.info(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {latest_path}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.weights_dir / "best_model.pth"
            torch.save(checkpoint, best_path)
            self.logger.info(f"ğŸ† ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
    
    def train_epoch(self, epoch: int) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_loss = 0.0
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch+1}/{self.config["epochs"]} - Training')
        
        for batch_idx, (signals, targets) in enumerate(pbar):
            try:
                signals = signals.to(self.device)
                targets = targets.to(self.device)
                
                # å‰å‘ä¼ æ’­
                self.optimizer.zero_grad()
                preds = self.model(signals)
                
                # è®¡ç®—æŸå¤±
                loss, loss_items = self.criterion(preds, targets, self.model)
                
                # æ£€æŸ¥æŸå¤±æ˜¯å¦æœ‰æ•ˆ
                if torch.isnan(loss) or torch.isinf(loss):
                    self.logger.warning(f"Warning: Invalid loss at batch {batch_idx}: {loss}")
                    continue
                
                # åå‘ä¼ æ’­
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(), 
                    max_norm=self.config.get('grad_clip', 1.0)
                )
                
                self.optimizer.step()
                
                # æ›´æ–°å­¦ä¹ ç‡ï¼ˆOneCycleLRï¼‰
                if isinstance(self.scheduler, optim.lr_scheduler.OneCycleLR):
                    self.scheduler.step()
                
                # è®°å½•æŸå¤±
                epoch_loss += loss.item()
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'loss': f'{loss.item():.4f}',
                    'box': f'{loss_items[0]:.4f}',
                    'cls': f'{loss_items[1]:.4f}',
                    'dfl': f'{loss_items[2]:.4f}',
                    'lr': f'{self.optimizer.param_groups[0]["lr"]:.6f}',
                })
                
                # è®°å½•åˆ°TensorBoard
                global_step = epoch * len(self.train_loader) + batch_idx
                self.writer.add_scalar('Loss/train_step', loss.item(), global_step)
                self.writer.add_scalar('LR/step', self.optimizer.param_groups[0]['lr'], global_step)
                
            except Exception as e:
                self.logger.error(f"è®­ç»ƒæ­¥éª¤å‡ºé”™ (batch {batch_idx}): {e}")
                continue
        
        return epoch_loss / len(self.train_loader)
    
    def validate(self, epoch: int) -> Tuple[float, float]:
        """éªŒè¯"""
        self.model.eval()
        val_loss = 0.0
        
        # é‡ç½®mAPæŒ‡æ ‡
        self.map_metric.reset()
        
        with torch.no_grad():
            pbar = tqdm(self.val_loader, desc=f'Epoch {epoch+1}/{self.config["epochs"]} - Validation')
            
            for batch_idx, (signals, targets) in enumerate(pbar):
                try:
                    signals = signals.to(self.device)
                    targets = targets.to(self.device)
                    
                    # å‰å‘ä¼ æ’­
                    preds = self.model(signals)
                    
                    # è®¡ç®—æŸå¤±
                    loss, loss_items = self.criterion(preds, targets, self.model)
                    val_loss += loss.item()
                    
                    # è®¡ç®—mAP
                    self._update_map_metric(preds, targets)
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({
                        'val_loss': f'{loss.item():.4f}',
                        'box': f'{loss_items[0]:.4f}',
                        'cls': f'{loss_items[1]:.4f}',
                        'dfl': f'{loss_items[2]:.4f}',
                    })
                    
                except Exception as e:
                    self.logger.error(f"éªŒè¯æ­¥éª¤å‡ºé”™ (batch {batch_idx}): {e}")
                    continue
        
        # è®¡ç®—å¹³å‡æŸå¤±å’ŒmAP
        avg_val_loss = val_loss / len(self.val_loader)
        
        # æ£€æŸ¥mAPæŒ‡æ ‡æ˜¯å¦æœ‰æ•°æ®
        try:
            mAP_result = self.map_metric.compute()
            mAP = mAP_result['map'].item()
                
        except Exception as e:
            self.logger.warning(f"mAPè®¡ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼0.0")
            mAP = 0.0
        
        return avg_val_loss, mAP
    
    def _update_map_metric(self, preds: List[Dict[str, torch.Tensor]], targets: torch.Tensor):
        """
        ä½¿ç”¨æ¥è‡ªpostprocess_for_metricsçš„é¢„æµ‹æ›´æ–°mAPæŒ‡æ ‡
        preds: ç»è¿‡åå¤„ç†çš„é¢„æµ‹åˆ—è¡¨ï¼Œå…¶åæ ‡ä¸ºç»å¯¹åæ ‡ (e.g., 0-1024)
        targets: åŸå§‹æ‰¹æ¬¡ç›®æ ‡å¼ é‡ï¼Œå…¶åæ ‡ä¸ºå½’ä¸€åŒ–åæ ‡ [0, 1]
        """
        # è½¬æ¢ç›®æ ‡ä»¥åŒ¹é…æŒ‡æ ‡æ ¼å¼
        processed_targets = []
        num_samples_in_batch = len(preds) # ä¿®æ­£: ä½¿ç”¨å®é™…æ‰¹æ¬¡å¤§å°

        for i in range(num_samples_in_batch): # ä¿®æ­£: éå†å®é™…æ ·æœ¬æ•°
            mask = targets[:, 0] == i
            batch_targets = targets[mask]
            
            if batch_targets.shape[0] > 0:
                # [class, x_center, width] -> [x1, y1, x2, y2]
                #
                # --- åæ ‡ç³»å¯¹é½ (å…³é”®) ---
                # postprocess_for_metrics è¾“å‡ºçš„é¢„æµ‹æ¡†(preds)æ˜¯ç»å¯¹åæ ‡ (0 to input_length)ã€‚
                # è€Œä»DataLoaderåŠ è½½çš„æ ‡ç­¾(targets)æ˜¯å½’ä¸€åŒ–åæ ‡ (0 to 1)ã€‚
                # å› æ­¤ï¼Œåœ¨è®¡ç®—mAPä¹‹å‰ï¼Œå¿…é¡»å°†çœŸå®æ ‡ç­¾(GT)çš„åæ ‡ä¹˜ä»¥input_lengthï¼Œ
                # å°†å…¶ä»"å½’ä¸€åŒ–"è½¬æ¢ä¸º"ç»å¯¹åæ ‡"ï¼Œä»¥åŒ¹é…é¢„æµ‹æ¡†çš„åæ ‡ç³»ã€‚
                #
                input_len = self.config['input_length']
                boxes_x1 = (batch_targets[:, 2] - batch_targets[:, 3] / 2) * input_len
                boxes_x2 = (batch_targets[:, 2] + batch_targets[:, 3] / 2) * input_len
                boxes_xyxy = torch.stack([boxes_x1, torch.zeros_like(boxes_x1), boxes_x2, torch.ones_like(boxes_x1)], dim=1)
                
                processed_targets.append({
                    'boxes': boxes_xyxy,
                    'labels': batch_targets[:, 1].long()
                })
            else:
                 processed_targets.append({
                    'boxes': torch.empty(0, 4, device=self.device),
                    'labels': torch.empty(0, dtype=torch.long, device=self.device)
                })

        try:
            # ç°åœ¨ preds å’Œ processed_targets çš„é•¿åº¦ä¿è¯ä¸€è‡´
            self.map_metric.update(preds, processed_targets)
        except Exception as e:
            self.logger.warning(f"æ›´æ–°mAPæŒ‡æ ‡æ—¶å‡ºé”™: {e}")

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹è®­ç»ƒ")
        self.logger.info(f"è®¾å¤‡: {self.device}")
        self.logger.info(f"è®­ç»ƒè½®æ•°: {self.config['epochs']}")
        self.logger.info(f"æ‰¹å¤§å°: {self.config['batch_size']}")
        self.logger.info(f"å­¦ä¹ ç‡: {self.config['learning_rate']}")
        
        for epoch in range(self.start_epoch, self.config['epochs']):
            try:
                # è®­ç»ƒ
                train_loss = self.train_epoch(epoch)
                self.train_losses.append(train_loss)
                
                # éªŒè¯
                val_loss, mAP = self.validate(epoch)
                self.val_losses.append(val_loss)
                self.mAPs.append(mAP)
                
                # æ›´æ–°å­¦ä¹ ç‡ï¼ˆéOneCycleLRï¼‰
                if not isinstance(self.scheduler, optim.lr_scheduler.OneCycleLR):
                    self.scheduler.step()
                
                # è®°å½•åˆ°TensorBoard
                self.writer.add_scalar('Loss/train_epoch', train_loss, epoch)
                self.writer.add_scalar('Loss/val_epoch', val_loss, epoch)
                self.writer.add_scalar('Metrics/mAP', mAP, epoch)
                self.writer.add_scalar('LR/epoch', self.optimizer.param_groups[0]['lr'], epoch)
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                is_best = mAP > self.best_map
                if is_best:
                    self.best_map = mAP
                
                self.save_checkpoint(epoch, is_best)
                
                # æ—©åœæ£€æŸ¥
                if self.early_stopping(val_loss):
                    self.logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
                    break
                
                self.logger.info(
                    f"Epoch {epoch+1}/{self.config['epochs']} - "
                    f"Train Loss: {train_loss:.4f}, "
                    f"Val Loss: {val_loss:.4f}, "
                    f"mAP: {mAP:.4f}, "
                    f"Best mAP: {self.best_map:.4f}"
                )
                
            except Exception as e:
                self.logger.error(f"è®­ç»ƒepoch {epoch+1} å‡ºé”™: {e}")
                continue
        
        self.logger.info("âœ… è®­ç»ƒå®Œæˆ")
        self.writer.close()


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')
    
    def __call__(self, val_loss: float) -> bool:
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
        
        return self.counter >= self.patience


class YOLO1DTrainer(BaseTrainer):
    """YOLO1Dè®­ç»ƒå™¨ï¼Œè¦†ç›–ç‰¹å®šæ–¹æ³•"""
    
    def __init__(self, 
                 train_loader: torch.utils.data.DataLoader,
                 val_loader: torch.utils.data.DataLoader,
                 config: Dict[str, Any],
                 device: torch.device,
                 resume_from: Optional[str] = None):
        
        # 1. åˆ›å»ºæ¨¡å‹
        model = create_yolo1d_model(
            model_size=config['model_size'],
            num_classes=config['num_classes'],
            input_channels=config['input_channels'],
            input_length=config['input_length'],
            reg_max=config.get('reg_max', 16)
        )
        
        super().__init__(model, train_loader, val_loader, config, device, resume_from)

    def _update_map_metric(self, preds: List[Dict[str, torch.Tensor]], targets: torch.Tensor):
        """
        ä½¿ç”¨æ¥è‡ªpostprocess_for_metricsçš„é¢„æµ‹æ›´æ–°mAPæŒ‡æ ‡
        preds: ç»è¿‡åå¤„ç†çš„é¢„æµ‹åˆ—è¡¨ï¼Œå…¶åæ ‡ä¸ºç»å¯¹åæ ‡ (e.g., 0-1024)
        targets: åŸå§‹æ‰¹æ¬¡ç›®æ ‡å¼ é‡ï¼Œå…¶åæ ‡ä¸ºå½’ä¸€åŒ–åæ ‡ [0, 1]
        """
        # è½¬æ¢ç›®æ ‡ä»¥åŒ¹é…æŒ‡æ ‡æ ¼å¼
        processed_targets = []
        num_samples_in_batch = len(preds) # ä¿®æ­£: ä½¿ç”¨å®é™…æ‰¹æ¬¡å¤§å°

        for i in range(num_samples_in_batch): # ä¿®æ­£: éå†å®é™…æ ·æœ¬æ•°
            mask = targets[:, 0] == i
            batch_targets = targets[mask]
            
            if batch_targets.shape[0] > 0:
                # [class, x_center, width] -> [x1, y1, x2, y2]
                #
                # --- åæ ‡ç³»å¯¹é½ (å…³é”®) ---
                # postprocess_for_metrics è¾“å‡ºçš„é¢„æµ‹æ¡†(preds)æ˜¯ç»å¯¹åæ ‡ (0 to input_length)ã€‚
                # è€Œä»DataLoaderåŠ è½½çš„æ ‡ç­¾(targets)æ˜¯å½’ä¸€åŒ–åæ ‡ (0 to 1)ã€‚
                # å› æ­¤ï¼Œåœ¨è®¡ç®—mAPä¹‹å‰ï¼Œå¿…é¡»å°†çœŸå®æ ‡ç­¾(GT)çš„åæ ‡ä¹˜ä»¥input_lengthï¼Œ
                # å°†å…¶ä»"å½’ä¸€åŒ–"è½¬æ¢ä¸º"ç»å¯¹åæ ‡"ï¼Œä»¥åŒ¹é…é¢„æµ‹æ¡†çš„åæ ‡ç³»ã€‚
                #
                input_len = self.config['input_length']
                boxes_x1 = (batch_targets[:, 2] - batch_targets[:, 3] / 2) * input_len
                boxes_x2 = (batch_targets[:, 2] + batch_targets[:, 3] / 2) * input_len
                boxes_xyxy = torch.stack([boxes_x1, torch.zeros_like(boxes_x1), boxes_x2, torch.ones_like(boxes_x1)], dim=1)
                
                processed_targets.append({
                    'boxes': boxes_xyxy,
                    'labels': batch_targets[:, 1].long()
                })
            else:
                 processed_targets.append({
                    'boxes': torch.empty(0, 4, device=self.device),
                    'labels': torch.empty(0, dtype=torch.long, device=self.device)
                })

        try:
            # ç°åœ¨ preds å’Œ processed_targets çš„é•¿åº¦ä¿è¯ä¸€è‡´
            self.map_metric.update(preds, processed_targets)
        except Exception as e:
            self.logger.warning(f"æ›´æ–°mAPæŒ‡æ ‡æ—¶å‡ºé”™: {e}")

    def validate(self, epoch: int) -> Tuple[float, float]:
        """
        éªŒè¯æ¨¡å‹ - ä¸train_simple.pyå¯¹é½çš„ç®€åŒ–ç‰ˆæœ¬
        """
        self.model.train()  # å…³é”®: ä¿æŒè®­ç»ƒæ¨¡å¼ä»¥è·å¾—åŸå§‹è¾“å‡º
        total_loss = 0.0
        
        pbar = tqdm(self.val_loader, desc=f"Validating Epoch {epoch+1}", leave=False)
        with torch.no_grad():
            for signals, targets in pbar:
                signals = signals.to(self.device)
                targets = targets.to(self.device)

                # 1. å‰å‘ä¼ æ’­
                preds_raw = self.model(signals)
                
                # 2. è®¡ç®—æŸå¤± (ä¿®æ­£: ç›´æ¥è°ƒç”¨criterionå¹¶ä¼ å…¥model)
                loss, _ = self.criterion(preds_raw, targets, self.model)
                total_loss += loss.item()

                # 3. åå¤„ç†ä»¥è®¡ç®—mAP
                # ä½¿ç”¨conf_thresh=0.001, iou_thresh=0.6ä½œä¸ºæ ‡å‡†éªŒè¯è®¾ç½®
                processed_preds = postprocess_for_metrics(preds_raw, self.model, conf_thresh=0.001, iou_thresh=0.6)

                # 4. æ›´æ–°mAPæŒ‡æ ‡
                self._update_map_metric(processed_preds, targets)
        
        # è®¡ç®—å¹³å‡æŸå¤±å’ŒmAP
        avg_loss = total_loss / len(self.val_loader)
        
        try:
            map_stats = self.map_metric.compute()
            mAP = map_stats['map_50'].item()
            self.map_metric.reset()
        except Exception as e:
            self.logger.error(f"è®¡ç®—mAPæ—¶å‡ºé”™: {e}")
            mAP = 0.0

        # éªŒè¯åæ— éœ€åˆ‡æ¢æ¨¡å¼ï¼Œå› ä¸ºæˆ‘ä»¬ä¸€ç›´å¤„äºtrain()æ¨¡å¼
        return avg_loss, mAP 