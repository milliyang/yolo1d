#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„YOLO1Dè®­ç»ƒè„šæœ¬
ç»“åˆtrain_simple.pyçš„æˆåŠŸç»éªŒï¼Œæå‡è®­ç»ƒæ•ˆæœ
"""

import torch
import torch.utils.data as data
import argparse
import sys
import os
from pathlib import Path
import numpy as np

from trainer_base import YOLO1DTrainer, ConfigManager, YOLO1DError
from dataset_generator import SinWaveDataset, collate_fn


class DataAugmentation:
    """æ•°æ®å¢å¼ºç±» - ä»train_simple.pyç§»æ¤"""
    def __init__(self, noise_std=0.02, scale_range=(0.9, 1.1)):
        self.noise_std = noise_std
        self.scale_range = scale_range
    
    def __call__(self, signal):
        # æ·»åŠ å™ªå£°
        if self.noise_std > 0:
            noise = np.random.normal(0, self.noise_std, signal.shape)
            signal = signal + noise
        
        # ç¼©æ”¾
        if self.scale_range:
            scale = np.random.uniform(self.scale_range[0], self.scale_range[1])
            signal = signal * scale
        
        return signal


class AugmentedSinWaveDataset(SinWaveDataset):
    """æ”¯æŒæ•°æ®å¢å¼ºçš„SinWaveDataset"""
    def __init__(self, dataset_path, split='train', input_length=1024, transform=None):
        super().__init__(dataset_path, split, input_length, transform)
    
    def __getitem__(self, idx):
        signal = self.signals[idx]
        
        if self.transform:
            signal = self.transform(signal)
        
        # è½¬æ¢ä¸ºå¼ é‡
        signal = torch.FloatTensor(signal).unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦ [1, sequence_length]
        
        # å¤„ç†æ ‡ç­¾ - è½¬æ¢ä¸ºYOLOæ ¼å¼ [image_idx, class, x_center, width]
        sample_labels = self.labels[idx]
        if sample_labels:
            targets = []
            for label in sample_labels:
                class_id, x_center, width = label
                targets.append([idx, class_id, x_center, width])
            targets = torch.FloatTensor(targets)
        else:
            targets = torch.zeros(0, 4)  # ç©ºæ ‡ç­¾
        
        return signal, targets


def setup_device():
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"ğŸš€ ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    else:
        device = torch.device('cpu')
        print("ğŸ’» ä½¿ç”¨CPU")
    
    return device


def create_data_loaders(config):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨ - æ”¯æŒæ•°æ®å¢å¼º"""
    print("ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    
    # æ•°æ®é›†è·¯å¾„
    dataset_path = config['dataset_path']
    
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}")
        print("è¯·å…ˆè¿è¡Œ dataset_generator.py ç”Ÿæˆæ•°æ®é›†")
        sys.exit(1)
    
    # æ•°æ®å¢å¼ºé…ç½®
    data_aug_config = config.get('data_augmentation', {})
    use_augmentation = data_aug_config.get('enabled', False)
    
    if use_augmentation:
        print("ğŸ”§ å¯ç”¨æ•°æ®å¢å¼º")
        train_transform = DataAugmentation(
            noise_std=data_aug_config.get('noise_std', 0.02),
            scale_range=tuple(data_aug_config.get('scale_range', [0.9, 1.1]))
        )
        val_transform = None
    else:
        train_transform = None
        val_transform = None
    
    # åˆ›å»ºè®­ç»ƒé›†
    train_dataset = AugmentedSinWaveDataset(
        dataset_path=dataset_path,
        split='train',
        input_length=config['input_length'],
        transform=train_transform
    )
    
    # åˆ›å»ºéªŒè¯é›†
    val_dataset = AugmentedSinWaveDataset(
        dataset_path=dataset_path,
        split='val',
        input_length=config['input_length'],
        transform=val_transform
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨è‡ªå®šä¹‰collate_fn
    train_loader = data.DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config.get('num_workers', 4),
        pin_memory=True if torch.cuda.is_available() else False,
        collate_fn=collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰collateå‡½æ•°
    )
    
    val_loader = data.DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config.get('num_workers', 4),
        pin_memory=True if torch.cuda.is_available() else False,
        collate_fn=collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰collateå‡½æ•°
    )
    
    return train_loader, val_loader


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–çš„YOLO1Dè®­ç»ƒè„šæœ¬')
    parser.add_argument('--config', type=str, default='config_optimized.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', type=str, default=None,
                       help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--run-name', type=str, default=None,
                       help='å®éªŒè¿è¡Œåç§°')
    
    args = parser.parse_args()
    
    try:
        print("ğŸ¯ ä¼˜åŒ–çš„YOLO1Dè®­ç»ƒè„šæœ¬")
        print("=" * 50)
        
        # 1. åŠ è½½é…ç½®
        print(f"ğŸ“‹ åŠ è½½é…ç½®: {args.config}")
        config_manager = ConfigManager(args.config)
        config = config_manager.get_training_config()
        
        # æ›´æ–°è¿è¡Œåç§°
        if args.run_name:
            config['run_name'] = args.run_name
        
        print(f"æ¨¡å‹å°ºå¯¸: {config['model_size']}")
        print(f"ç±»åˆ«æ•°: {config['num_classes']}")
        print(f"è¾“å…¥é•¿åº¦: {config['input_length']}")
        print(f"è®­ç»ƒè½®æ•°: {config['epochs']}")
        print(f"æ‰¹å¤§å°: {config['batch_size']}")
        print(f"å­¦ä¹ ç‡: {config['learning_rate']}")
        
        # æ˜¾ç¤ºæŸå¤±æƒé‡
        hyp = config.get('hyp', {})
        print(f"æŸå¤±æƒé‡: box={hyp.get('box', 7.5)}, cls={hyp.get('cls', 0.5)}, dfl={hyp.get('dfl', 1.5)}")
        
        # æ˜¾ç¤ºæ•°æ®å¢å¼ºçŠ¶æ€
        data_aug_config = config.get('data_augmentation', {})
        if data_aug_config.get('enabled', False):
            print(f"æ•°æ®å¢å¼º: å¯ç”¨ (å™ªå£°={data_aug_config.get('noise_std', 0.02)}, ç¼©æ”¾={data_aug_config.get('scale_range', [0.9, 1.1])})")
        else:
            print("æ•°æ®å¢å¼º: ç¦ç”¨")
        
        # 2. è®¾ç½®è®¾å¤‡
        device = setup_device()
        
        # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader = create_data_loaders(config)
        
        # 4. åˆ›å»ºè®­ç»ƒå™¨
        print("ğŸ—ï¸ åˆ›å»ºè®­ç»ƒå™¨...")
        trainer = YOLO1DTrainer(
            train_loader=train_loader,
            val_loader=val_loader,
            config=config,
            device=device,
            resume_from=args.resume
        )
        
        # 5. å¼€å§‹è®­ç»ƒ
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        
    except YOLO1DError as e:
        print(f"âŒ YOLO1Dé”™è¯¯: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 